{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 下面开始机器学习\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据集来咯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_x', 'test_x', 'train_y', 'test_y']\n",
      "(23877, 1)\n"
     ]
    }
   ],
   "source": [
    "with np.load('唐诗处理后数据集.npz', allow_pickle=True) as data:\n",
    "    print(data.files)\n",
    "    train_x,test_x,train_y,test_y = data['train_x'], data['test_x'], data['train_y'], data['test_y']\n",
    "print(train_x.shape)\n",
    "# train_x.astype(int)\n",
    "# train_x.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解读回去"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "['，',\n '。',\n '十',\n '卷',\n '百',\n '一',\n '不',\n '人',\n '三',\n '二',\n '四',\n '五',\n '山',\n '日',\n '六',\n '無',\n '八',\n '七',\n '風',\n '中',\n '上',\n '雲',\n '有',\n '九',\n '春',\n '白',\n '天',\n '何',\n '來',\n '月',\n '花',\n '水',\n '時',\n '相',\n '長',\n '君',\n '歸',\n '秋',\n '年',\n '為',\n '生',\n '自',\n '行',\n '江',\n '見',\n '夜',\n '心',\n '知',\n '李',\n '如',\n '此',\n '得',\n '清',\n '下',\n '高',\n '去',\n '南',\n '空',\n '明',\n '在',\n '子',\n '門',\n '事',\n '客',\n '送',\n '道',\n '未',\n '處',\n '居',\n '東',\n '別',\n '金',\n '歌',\n '王',\n '多',\n '青',\n '是',\n '寒',\n '玉',\n '城',\n '雨',\n '遠',\n '朝',\n '家',\n '落',\n '新',\n '出',\n '今',\n '與',\n '西',\n '應',\n '寄',\n '陽',\n '思',\n '千',\n '前',\n '聲',\n '入',\n '書',\n '路',\n '萬',\n '馬',\n '望',\n '草',\n '我',\n '同',\n '飛',\n '深',\n '樹',\n '和',\n '流',\n '開',\n '將',\n '盡',\n '酒',\n '獨',\n '還',\n '已',\n '聞',\n '回',\n '成',\n '地',\n '煙',\n '光',\n '詩',\n '公',\n '重',\n '可',\n '石',\n '誰',\n '色',\n '林',\n '欲',\n '從',\n '雪',\n '古',\n '作',\n '州',\n '方',\n '向',\n '更',\n '之',\n '：',\n '海',\n '首',\n '樓',\n '看',\n '舊',\n '老',\n '易',\n '張',\n '情',\n '滿',\n '身',\n '然',\n '後',\n '愁',\n '香',\n '名',\n '過',\n '言',\n '黃',\n '衣',\n '能',\n '外',\n '遊',\n '頭',\n '平',\n '起',\n '樂',\n '難',\n '塵',\n '龍',\n '曲',\n '裏',\n '大',\n '安',\n '莫',\n '紅',\n '北',\n '華',\n '松',\n '仙',\n '閑',\n '分',\n '故',\n '複',\n '到',\n '似',\n '初',\n '懷',\n '晚',\n '少',\n '宮',\n '葉',\n '猶',\n '離',\n '當',\n '零',\n '竹',\n '氣',\n '意',\n '題',\n '鳥',\n '柳',\n '贈',\n '因',\n '間',\n '劉',\n '非',\n '文',\n '辭',\n '亦',\n '吟',\n '元',\n '國',\n '邊',\n '暮',\n '所',\n '幾',\n '池',\n '夢',\n '留',\n '漢',\n '孤',\n '餘',\n '逢',\n '問',\n '溪',\n '寺',\n '庭',\n '隱',\n '杜',\n '里',\n '士',\n '—',\n '陰',\n '河',\n '醉',\n '野',\n '隨',\n '物',\n '神',\n '關',\n '世',\n '登',\n '歲',\n '枝',\n '幽',\n '臨',\n '微',\n '泉',\n '坐',\n '露',\n '使',\n '若',\n '終',\n '發',\n '期',\n '小',\n '宿',\n '休',\n '經',\n '鄉',\n '芳',\n '好',\n '霜',\n '台',\n '輕',\n '憶',\n '以',\n '至',\n '早',\n '碧',\n '連',\n '陵',\n '綠',\n '半',\n '波',\n '鶴',\n '太',\n '郎',\n '才',\n '官',\n '亭',\n '先',\n '共',\n '正',\n '對',\n '合',\n '者',\n '近',\n '尋',\n '曾',\n '吹',\n '照',\n '舟',\n '豈',\n '兩',\n '曉',\n '夕',\n '常',\n '影',\n '羅',\n '翠',\n '遙',\n '楚',\n '雙',\n '苦',\n '須',\n '峰',\n '驚',\n '主',\n '園',\n '沙',\n '殘',\n '斷',\n '師',\n '僧',\n '楊',\n '動',\n '靜',\n '悲',\n '木',\n '垂',\n '景',\n '興',\n '卻',\n '川',\n '病',\n '恩',\n '紫',\n '德',\n '吳',\n '奉',\n '章',\n '堂',\n '湖',\n '靈',\n '又',\n '語',\n '絕',\n '久',\n '依',\n '真',\n '鳳',\n '蕭',\n '女',\n '鳴',\n '浮',\n '笑',\n '聽',\n '吾',\n '魚',\n '蒼',\n '皇',\n '忽',\n '通',\n '秦',\n '尚',\n '唯',\n '府',\n '車',\n '丹',\n '甫',\n '星',\n '憐',\n '傳',\n '愛',\n '詠',\n '齊',\n '群',\n '淚',\n '侍',\n '郊',\n '虛',\n '田',\n '帝',\n '游',\n '數',\n '夫',\n '寂',\n '聖',\n '許',\n '昔',\n '會',\n '且',\n '閣',\n '雁',\n '舞',\n '句',\n '只',\n '令',\n '轉',\n '堪',\n '節',\n '洞',\n '散',\n '其',\n '恨',\n '武',\n '軍',\n '往',\n '謝',\n '窮',\n '親',\n '疏',\n '征',\n '蘭',\n '朱',\n '直',\n '胡',\n '說',\n '涼',\n '悠',\n '亂',\n '用',\n '感',\n '始',\n '度',\n '容',\n '桃',\n '火',\n '洛',\n '信',\n '遲',\n '韋',\n '覺',\n '窗',\n '韓',\n '觀',\n '待',\n '賢',\n '足',\n '禦',\n '燕',\n '手',\n '畫',\n '傷',\n '霞',\n '宴',\n '晴',\n '死',\n '喜',\n '勝',\n '學',\n '功',\n '琴',\n '劍',\n '皆',\n '暗',\n '酬',\n '移',\n '顧',\n '即',\n '雖',\n '步',\n '陳',\n '及',\n '帶',\n '識',\n '崔',\n '結',\n '立',\n '珠',\n '塞',\n '岩',\n '顏',\n '羽',\n '逐',\n '周',\n '都',\n '卿',\n '臥',\n '幹',\n '願',\n '歡',\n '徒',\n '岸',\n '食',\n '桂',\n '兒',\n '命',\n '廟',\n '斜',\n '司',\n '隔',\n '友',\n '含',\n '夏',\n '鏡',\n '京',\n '繞',\n '橫',\n '遺',\n '解',\n '殿',\n '湘',\n '棲',\n '孟',\n '倚',\n '盧',\n '禪',\n '己',\n '絲',\n '雜',\n '浪',\n '憂',\n '兵',\n '美',\n '化',\n '玄',\n '舍',\n '於',\n '杯',\n '乘',\n '諸',\n '貴',\n '荒',\n '陸',\n '跡',\n '定',\n '交',\n '薄',\n '疑',\n '爾',\n '徐',\n '本',\n '闕',\n '藥',\n '越',\n '異',\n '飲',\n '商',\n '求',\n '兼',\n '便',\n '惜',\n '拂',\n '爭',\n '騎',\n '臣',\n '鐘',\n '賦',\n '詞',\n '口',\n '忘',\n '錦',\n '翻',\n '勞',\n '燈',\n '頻',\n '兮',\n '端',\n '郡',\n '著',\n '鄭',\n '眼',\n '啼',\n '飄',\n '守',\n '素',\n '念',\n '蒙',\n '第',\n '迎',\n '孫',\n '映',\n '侯',\n '猿',\n '徑',\n '力',\n '榮',\n '音',\n '苔',\n '任',\n '沉',\n '錢',\n '錫',\n '鄰',\n '遇',\n '參',\n '韻',\n '字',\n '史',\n '圖',\n '赴',\n '良',\n '教',\n '梁',\n '惟',\n '極',\n '橋',\n '他',\n '凝',\n '院',\n '船',\n '冷',\n '戰',\n '閒',\n '軒',\n '由',\n '引',\n '禮',\n '弦',\n '永',\n '稀',\n '衰',\n '條',\n '報',\n '折',\n '蓮',\n '悵',\n '搖',\n '住',\n '載',\n '幸',\n '況',\n '罷',\n '目',\n '村',\n '暖',\n '貧',\n '制',\n '細',\n '息',\n '歎',\n '壁',\n '嶺',\n '偏',\n '原',\n '裴',\n '蓬',\n '怨',\n '滄',\n '但',\n '鼓',\n '臺',\n '齋',\n '想',\n '蜀',\n '建',\n '掩',\n '緣',\n '偶',\n '魂',\n '持',\n '內',\n '論',\n '彩',\n '取',\n '漸',\n '接',\n '禹',\n '宜',\n '眠',\n '梅',\n '宅',\n '暫',\n '舉',\n '洲',\n '變',\n '寶',\n '沈',\n '低',\n '鬢',\n '破',\n '紛',\n '佳',\n '戶',\n '訪',\n '宗',\n '釣',\n '面',\n '懸',\n '房',\n '冰',\n '穀',\n '皎',\n '簾',\n '俗',\n '尊',\n '鶯',\n '泛',\n '封',\n '精',\n '館',\n '片',\n '失',\n '晨',\n '骨',\n '傾',\n '島',\n '業',\n '帆',\n '雞',\n '虎',\n '曹',\n '井',\n '獻',\n '浦',\n '攜',\n '弟',\n '代',\n '傍',\n '吏',\n '枕',\n '鴻',\n '龜',\n '秀',\n '既',\n '丘',\n '土',\n '漁',\n '昏',\n '室',\n '迷',\n '盤',\n '賞',\n '賈',\n '唐',\n '理',\n '必',\n '荊',\n '伴',\n '泥',\n '蟬',\n '承',\n '翁',\n '眉',\n '冥',\n '旅',\n '揚',\n '積',\n '詳',\n '渡',\n '根',\n '茲',\n '冠',\n '氏',\n '源',\n '冬',\n '采',\n '盛',\n '陶',\n '再',\n '籍',\n '仍',\n '機',\n '賓',\n '縣',\n '渾',\n '收',\n '管',\n '蘇',\n '敢',\n '雄',\n '浩',\n '鬥',\n '床',\n '眾',\n '志',\n '英',\n '途',\n '階',\n '全',\n '急',\n '薛',\n '狂',\n '溫',\n '牧',\n '嚴',\n '拜',\n '趙',\n '藏',\n '殊',\n '指',\n '稱',\n '那',\n '最',\n '繁',\n '腸',\n '茫',\n '霧',\n '適',\n '殷',\n '種',\n '融',\n '旗',\n '賀',\n '戎',\n '廣',\n '性',\n '席',\n '竟',\n '比',\n '衡',\n '每',\n '遂',\n '嘉',\n '形',\n '涯',\n '象',\n '閉',\n '哀',\n '烏',\n '修',\n '侵',\n '旌',\n '乃',\n '慚',\n '荷',\n '昭',\n '寥',\n '維',\n '澤',\n '昨',\n '于',\n '列',\n '牛',\n '尺',\n '燭',\n '髮',\n '恐',\n '銀',\n '各',\n '攀',\n '次',\n '津',\n '戴',\n '抱',\n '憑',\n '答',\n '省',\n '被',\n '姚',\n '苑',\n '危',\n '淒',\n '投',\n '桑',\n '筆',\n '莊',\n '曙',\n '郭',\n '惆',\n '調',\n '放',\n '哭',\n '把',\n '集',\n '寧',\n '宵',\n '角',\n '童',\n '貫',\n '喧',\n '屋',\n '降',\n '負',\n '法',\n '計',\n '營',\n '甘',\n '銷',\n '遍',\n '淩',\n '塘',\n '禁',\n '叢',\n '岑',\n '嗟',\n '消',\n '並',\n '夷',\n '縱',\n '濕',\n '谷',\n '輪',\n '昌',\n '菊',\n '駕',\n '招',\n '篇',\n '瑤',\n '驛',\n '毛',\n '沒',\n '淮',\n '潭',\n '廬',\n '鸞',\n '短',\n '兄',\n '嶽',\n '誠',\n '走',\n '幕',\n '漏',\n '斯',\n '點',\n '淺',\n '而',\n '員',\n '勢',\n '宣',\n '程',\n '潮',\n '仁',\n '赤',\n '催',\n '茅',\n '奇',\n '盈',\n '勤',\n '輿',\n '晝',\n '蓋',\n '筵',\n '戲',\n '繡',\n '巴',\n '達',\n '陪',\n '枯',\n '豔',\n '弄',\n '澗',\n '愈',\n '霄',\n '雷',\n '綺',\n '渚',\n '粉',\n '禽',\n '陌',\n '漫',\n '慶',\n '沾',\n '存',\n '瓊',\n '驅',\n '巢',\n '掃',\n '強',\n '肯',\n '淨',\n '妾',\n '妝',\n '峽',\n '叔',\n '俱',\n '籠',\n '披',\n '義',\n '潛',\n '棹',\n '丞',\n '利',\n '壯',\n '益',\n '燒',\n '延',\n '升',\n '避',\n '疾',\n '輝',\n '迢',\n '佩',\n '響',\n '羨',\n '宋',\n '試',\n '爐',\n '遣',\n '銜',\n '□',\n '稹',\n '桐',\n '呈',\n '借',\n '掛',\n '壽',\n '襟',\n '背',\n '奏',\n '權',\n '詔',\n '擬',\n '境',\n '滴',\n '底',\n '也',\n '服',\n '滅',\n '唱',\n '聊',\n '圓',\n '除',\n '威',\n ...]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('中文到整数转换表.json') as f:\n",
    "    j = json.load(f)\n",
    "    # print(j)\n",
    "    整数到中文转换表 = ['' for i in range(len(j))]\n",
    "    for (汉字, 数字) in j.items():\n",
    "        整数到中文转换表[数字] = 汉字\n",
    "整数到中文转换表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": "'朱藤朱藤，溫如紅玉，直如朱繩。自我得爾以為杖，中途不進，部曲多回。唯此朱藤，實隨我來。瘴癘之鄉，或水或陸，自北徂南。泥黏雪滑，足力不堪。吾本兩足，吾與爾披雲撥水，環山繞野。二年蹋遍匡廬間，'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.csdn.net/gavin_john/article/details/50717695 中括号取item运算符重载\n",
    "def decode_poetry(num_array):\n",
    "    return \"\".join(map(整数到中文转换表.__getitem__, num_array))\n",
    "a = train_x[2200]\n",
    "print(a.dtype)\n",
    "# print(a)\n",
    "# a[0]\n",
    "decode_poetry(a[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "['白居易',\n '杜甫',\n '李白',\n '齊己',\n '劉禹錫',\n '元稹',\n '李商隱',\n '貫休',\n '韋應物',\n '陸龜蒙',\n '劉長卿',\n '許渾',\n '皎然',\n '杜牧',\n '羅隱',\n '張籍',\n '姚合',\n '錢起',\n '賈島',\n '孟郊',\n '王建',\n '岑參',\n '韓愈',\n '張祜',\n '皮日休',\n '王維',\n '溫庭筠',\n '權德輿',\n '方幹',\n '韋莊',\n '杜荀鶴',\n '盧綸',\n '韓偓',\n '張說',\n '戴叔倫',\n '李中',\n '吳融',\n '李端',\n '薛能',\n '孟浩然',\n '趙嘏',\n '徐鉉',\n '徐夤',\n '皇甫冉',\n '李群玉',\n '李賀',\n '顧況',\n '司空圖',\n '高適',\n '李嶠',\n '李頻',\n '鄭穀',\n '黃滔',\n '施肩吾',\n '周曇',\n '張九齡',\n '宋之問',\n '武元衡',\n '鮑溶',\n '耿湋',\n '李益',\n '儲光羲',\n '司空曙',\n '沈佺期',\n '王昌齡',\n '柳宗元',\n '馬戴',\n '朱慶餘',\n '張喬',\n '李洞',\n '唐彥謙',\n '韓翃',\n '胡曾',\n '楊巨源',\n '曹松',\n '羅鄴',\n '李鹹用',\n '劉得仁',\n '許棠',\n '李德裕',\n '李嘉佑',\n '李頎',\n '李紳',\n '駱賓王',\n '雍陶',\n '戎昱',\n '鄭谷',\n '劉商',\n '陳陶',\n '盧照鄰',\n '李涉',\n '呂岩',\n '蘇頲',\n '曹鄴',\n '呂溫',\n '劉滄',\n '張蠙',\n '崔塗',\n '項斯',\n '無可',\n '羊士諤',\n '周賀',\n '盧仝',\n '薛逢',\n '徐凝',\n '元結',\n '陳子昂',\n '李世民',\n '李建勳',\n '獨孤及',\n '王勃',\n '歐陽詹',\n '殷堯藩',\n '李山甫',\n '薛濤',\n '吳筠',\n '孫元晏',\n '劉駕',\n '劉兼',\n '郎士元',\n '顧非熊',\n '劉言史',\n '李郢',\n '嚴維',\n '章孝標',\n '崔道融',\n '王貞白',\n '李隆基',\n '喻鳧',\n '陳羽',\n '牟融',\n '楊衡',\n '孫逖',\n '汪遵',\n '裴夷直',\n '王周',\n '崔國輔',\n '常建',\n '令狐楚',\n '裴說',\n '於鵠',\n '于武陵',\n '段成式',\n '皇甫曾',\n '張繼',\n '高駢',\n '魚玄機',\n '武則天',\n '包佶',\n '崔顥',\n '崔峒',\n '王績',\n '李乂',\n '聶夷中',\n '賈至',\n '靈一',\n '杜審言',\n '曹唐',\n '張謂',\n '竇鞏',\n '譚用之',\n '楊凝',\n '儲嗣宗',\n '司馬紮',\n '李煜',\n '於濆',\n '秦韜玉',\n '虞世南',\n '秦系',\n '徐彥伯',\n '祖詠',\n '魏征',\n '孫光憲',\n '陸暢',\n '李遠',\n '李咸用',\n '唐求',\n '褚亮',\n '李昌符',\n '崔湜',\n '劉希夷',\n '高蟾',\n '楊炯',\n '姚鵠',\n '邵謁',\n '林寬',\n '尚顏',\n '李適',\n '王涯',\n '馮延巳',\n '張泌',\n '雍裕之',\n '翁承贊',\n '孟貫',\n '張仲素',\n '顏真卿',\n '熊孺登',\n '崔櫓',\n '裴度',\n '劉方平',\n '李百藥',\n '裴迪',\n '鄭巢',\n '盧肇',\n '來鵠',\n '蘇拯',\n '杜光庭',\n '許敬宗',\n '殷文圭',\n '劉憲',\n '朱放',\n '張南史',\n '劉叉',\n '劉威',\n '修睦',\n '歐陽炯',\n '盧象',\n '綦毋潛',\n '竇常',\n '沈亞之',\n '章碣',\n '鄭愔',\n '子蘭',\n '韓琮',\n '和凝',\n '周樸',\n '竇群',\n '朱灣',\n '於鄴',\n '喬知之',\n '長孫佐輔',\n '孫魴',\n '趙彥昭',\n '周繇',\n '伍喬',\n '清江',\n '毛文錫',\n '楊師道',\n '孟雲卿',\n '賀知章',\n '楊淩',\n '竇牟',\n '周朴',\n '陸希聲',\n '上官儀',\n '竇庠',\n '許彬',\n '成彥雄',\n '董思恭',\n '皇甫松',\n '蕭穎士',\n '包何',\n '楊憑',\n '李九齡',\n '胡宿',\n '李冶',\n '沈彬',\n '陶翰',\n '張子容',\n '郭震',\n '于鵠',\n '孟遲',\n '喻坦之',\n '任翻',\n '靈澈',\n '劉昚虛',\n '王翰',\n '王轂',\n '李珣',\n '崔融1',\n '趙冬曦',\n '張又新',\n '王初',\n '顧夐',\n '法振',\n '徐氏',\n '武平一',\n '梁鍠',\n '劉複',\n '朱景玄',\n '張賁',\n '廣宣',\n '棲白',\n '翁綬',\n '李華',\n '閻朝隱',\n '牛嶠',\n '蘇味道',\n '崔曙',\n '暢當',\n '張碧',\n '鄭畋',\n '褚載',\n '王仁裕',\n '劉昭禹',\n '蔣吉',\n '鄭遨',\n '虛中',\n '薛稷',\n '盧延讓',\n '崔日用',\n '莊南傑',\n '陳子良',\n '盧僎',\n '丘為',\n '李紓',\n '薛據',\n '王季友1',\n '丘丹',\n '盧殷',\n '楊發',\n '翁洮',\n '毛熙震',\n '丁仙芝',\n '馬懷素',\n '張諤',\n '徐安貞',\n '柳中庸',\n '薛存誠',\n '韋處厚',\n '陳去疾',\n '蔣防',\n '陳標',\n '薛瑩',\n '吳仁璧',\n '孔德紹',\n '楊夔',\n '護國',\n '棲蟾',\n '尹鶚',\n '徐堅',\n '于濆',\n '李廓',\n '鄭錫',\n '姚系',\n '王灣',\n '冷朝陽',\n '崔玨',\n '于鄴',\n '熊皎',\n '左偃',\n '水神',\n '袁暉',\n '王睿',\n '韋元旦',\n '盧鴻一',\n '常袞',\n '竇叔向',\n '李赤',\n '費冠卿',\n '韋蟾',\n '蔣貽恭',\n '可止',\n '李逢吉',\n '李約',\n '王縉',\n '萬楚',\n '李義府',\n '陳叔達',\n '武三思',\n '蕭至忠',\n '楊汝士',\n '崔涯',\n '歐陽袞',\n '李昭象',\n '盧士衡',\n '江為',\n '吳商浩',\n '處默',\n '李治',\n '姚崇',\n '孟簡',\n '韋承慶',\n '郎大家宋氏',\n '張文琮',\n '吳少微',\n '薛曜',\n '盧藏用',\n '包融',\n '陳潤',\n '鮑防',\n '張登',\n '李敬方',\n '顧雲',\n '孟賓於',\n '韓溉',\n '伊用昌',\n '薛昭蘊',\n '魏承班',\n '李顯',\n '李忱',\n '上官昭容',\n '鄭絪',\n '張袞',\n '張循之',\n '王無競',\n '王適',\n '厲玄',\n '薛奇童',\n '王諲',\n '張潮',\n '崔液',\n '張志和',\n '劉孝孫',\n '孔紹安',\n '宗楚客',\n '于季子',\n '韋嗣立',\n '賀朝',\n '蔣冽',\n '朱長文',\n '于良史',\n '陳翊',\n '崔元翰',\n '麹信陵',\n '李翱',\n '白行簡',\n '舒元輿',\n '霍總',\n '王駕',\n '錢珝',\n '劉象',\n '徐仲雅',\n '廖融',\n '史鳳',\n '閻選',\n '李昂1',\n '徐賢妃',\n '李衍',\n '賈曾',\n '牛僧孺',\n '李舒',\n '鄭世翼',\n '王之渙',\n '李暇',\n '張柬之',\n '李康成',\n '張彪',\n '田娥',\n '任希古',\n '宋璟',\n '張均',\n '岑羲',\n '胡皓',\n '張旭',\n '劉灣',\n '沈頌',\n '閻防',\n '嚴武',\n '章八元',\n '陳存',\n '崔護',\n '王起',\n '林滋',\n '李宣古',\n '鄭損',\n '李沇',\n '鄭准',\n '王岩',\n '馮道',\n '陳貺',\n '牛希濟',\n '詹敦仁',\n '王元',\n '張夫人',\n '張窈窕',\n '義淨',\n '歸仁',\n '可朋',\n '慕幽',\n '許堅2',\n '蜀宮群仙',\n '李貞白',\n '李璟',\n '段文昌',\n '張易之',\n '郭元振',\n '袁朗',\n '李嶷',\n '陸長源',\n '庾抱',\n '劉禕之',\n '徐晶',\n '李泌',\n '許景先',\n '蔡希寂',\n '殷遙',\n '王泠然',\n '崔興宗',\n '徐九皋',\n '閻寬',\n '于邵',\n '沈千運',\n '呂渭',\n '崔備',\n '徐敞',\n '張聿',\n '李正封',\n '鄭澣',\n '李程',\n '楊嗣複',\n '沈傳師',\n '周匡物',\n '袁不約',\n '楊乘',\n '趙璜',\n '潘鹹',\n '鄭綮',\n '歐陽玭',\n '公乘億',\n '盧汝弼',\n '楊凝式',\n '黃損',\n '韓熙載',\n '潘佑',\n '廖匡圖',\n '徐鍇',\n '許堅1',\n '湯悅',\n '吳越人',\n '李濤',\n '盧休',\n '李範',\n '晁采',\n '姚月華',\n '梁瓊',\n '趙鸞鸞',\n '慧淨',\n '隱巒',\n '雲台峰女仙',\n '陳季卿',\n '權龍褒',\n '文丙',\n '鮑君徽',\n '韓休',\n '郭子儀',\n '李回',\n '員半千',\n '許孟容',\n '崔邠',\n '趙光逢',\n '紀唐夫',\n '王偃',\n '辛弘智',\n '張紘',\n '韋渠牟',\n '岑文本',\n '陸敬',\n '楊浚',\n '劉允濟',\n '韓仲宣',\n '高瑾',\n '崔泰之',\n '魏知古',\n '王琚',\n '李迥秀',\n '趙彥伯',\n '源幹曜',\n '裴漼',\n '韋述',\n '劉庭琦',\n '張嘉貞',\n '席豫',\n '沈如筠',\n '李邕',\n '萬齊融',\n '蔣維翰',\n '孫昌胤',\n '張鼎',\n '馮著',\n '蔣渙',\n '元季川',\n '陸贄',\n '王烈',\n '奚賈',\n '謝良輔',\n '劉迥',\n '皇甫澈',\n '李吉甫',\n '李觀',\n '李絳',\n '姚康',\n '馬異',\n '裴次元',\n '王魯複',\n '李渤',\n '柳公權',\n '張蕭遠',\n '何希堯',\n '柳棠',\n '祝元膺',\n '王鐸',\n '李玖',\n '莫宣卿',\n '鄭愚',\n '袁郊',\n '蕭遘',\n '袁皓',\n '鄭仁表',\n '鄭璧',\n '溫憲',\n '孫偓',\n '路德延',\n '胡令能',\n '孫棨',\n '張為',\n '劉斌',\n '羅紹威',\n '宋齊丘',\n '廖凝',\n '李家明',\n '翁宏',\n '劉乙',\n '胡玢',\n '狄煥',\n '楊希道',\n '鄭鏦',\n '紇幹著',\n '周濆',\n '馬逢',\n '吉師老',\n '姚揆',\n '易思',\n '賈彥璋',\n '韓常侍',\n '陳甫',\n '卞震',\n '趙氏2',\n '薛馧',\n '張文姬',\n '步非煙',\n '孟氏',\n '崔萱',\n '崔仲容',\n '慧宣',\n '善生',\n '卿雲',\n '馬湘',\n '張辭',\n '沈廷瑞',\n '卓英英',\n '張元一',\n '李存勖',\n '鹿虔扆',\n '李亨',\n '錢鏐',\n '盧從願',\n '蔡孚',\n '盧懷慎',\n '劉晏',\n '鄭餘慶',\n '蕭仿',\n '馮伉',\n '賈馳',\n '鄭渥',\n '東方虯',\n '朱光弼',\n '杜頠',\n '齊浣',\n '張若虛',\n '李希仲',\n '賀蘭進明',\n '常理',\n '李景伯',\n '盧貞',\n '謝偃',\n '長孫無忌',\n '杜淹',\n '崔善為',\n '歐陽詢',\n '元萬頃',\n '陳元光',\n '崔知賢',\n '陳嘉言',\n '張敬忠',\n '張昌宗',\n '喬備',\n '尹懋',\n '李崇嗣',\n '韋安石',\n '李元紘',\n '王丘',\n '周瑀',\n '孫處玄',\n '徐延壽',\n '李憕',\n '李昂2',\n '李林甫',\n '陳希烈',\n '宋昱',\n '崔翹',\n '陸海',\n '沈宇',\n '張萬頃',\n '樓穎',\n '劉太真',\n '褚朝陽',\n '畢耀',\n '趙征明',\n '任華',\n '韓滉',\n '韋夏卿',\n '張眾甫',\n '丁澤',\n '王表',\n '何兆',\n '陸羽',\n '鄭常',\n '竇參',\n '韋皋',\n '崔子向',\n '柳公綽',\n '林藻',\n '張薦',\n '潘孟陽',\n '崔立之',\n '範傳正',\n '張賈',\n '張文規',\n '張匯',\n '陳通方',\n '皇甫湜',\n '盧拱',\n '劉猛',\n '葉季良',\n '湛賁',\n '周弘亮',\n '張仲方',\n '崔玄亮',\n '符載',\n '孫叔向',\n '劉皂',\n '林傑',\n '蔡京',\n '楊敬之',\n '陳至',\n '鄭還古',\n '朱晝',\n '滕邁',\n '李餘',\n '白敏中',\n '常楚老',\n '平曾',\n '魏扶',\n '楊收',\n '鄭史',\n '元晦',\n '黃頗',\n '劉綺莊',\n '楊牢',\n '潘緯',\n '武瓘',\n '李騭',\n '張孜',\n '趙鴻',\n '李縠',\n '顏萱',\n '顧在鎔',\n '王渙',\n '戴司顏',\n '孫合',\n '李琪',\n '盧頻',\n '鄭良士',\n '伍唐珪',\n '陳光',\n '捧劍僕',\n '黃巢',\n '羅袞',\n '鐘謨',\n '王感化',\n '馮涓',\n '楊玢',\n '詹琲',\n '張立',\n '蘇廣文',\n '尉遲匡',\n '繆島雲',\n '夏寶松',\n '庸仁傑',\n '李堯夫',\n '段義宗',\n '李舜弦',\n '王韞秀',\n '孫氏',\n '程長文',\n '崔鶯鶯',\n '劉雲',\n '張琰',\n '劉媛',\n '劉瑤',\n '廉氏',\n '關盼盼',\n '王福娘',\n '徐月英',\n '元淳',\n '寒山',\n '景雲',\n '法照',\n '知玄',\n '澹交',\n '若虛',\n '曇域',\n '幹康',\n '惟審',\n '許宣平',\n '李夢符',\n '張白',\n '眉娘',\n '上元夫人',\n '滕傳胤',\n '湘中蛟女',\n '龍女',\n '何光遠',\n '韋璜',\n '西施',\n '王軒',\n '劉行敏',\n '裴諝',\n '徐昌圖',\n '李旦',\n '李賢',\n '孟昶',\n '韓思複',\n '劉晃',\n '王晙',\n '崔玄童',\n '何鸞',\n '蔣挺',\n '源光裕',\n '姜皎',\n '薑晞',\n '夏侯孜',\n '張齊賢',\n '鄭善玉',\n '胡雄',\n '祝欽明',\n '陳京',\n '歸登',\n '杜羔',\n '張昭',\n '劉氏雲',\n '竇威',\n '歐陽瑾',\n '趙微明',\n '梁獻',\n '顧朝陽',\n '梁氏瓊',\n '吳燭',\n '張修之',\n '裴交泰',\n '嚴識玄',\n '張烜',\n '王沈',\n '柯崇',\n '鄒紹先',\n '虞羽客',\n '張熾',\n '王訓',\n '李章',\n '滕潛',\n '王珪',\n '杜正倫',\n '崔信明',\n '馬周',\n '張文恭',\n '李敬玄',\n '楊思玄',\n '杜易簡',\n '趙謙光',\n '張鷟',\n '魏元忠',\n '李懷遠',\n '蘇瑰',\n '高正臣',\n '高球',\n '弓嗣初',\n '長孫正隱',\n '周彥暉',\n '高嶠',\n '周思鈞',\n '崔日知',\n '楊廉',\n '張錫',\n '解琬',\n '蕭嵩',\n '陸堅',\n '李適之',\n '鄭繇',\n '蘇晉',\n '王光庭',\n '裴耀卿',\n '宋鼎',\n '張宣明',\n '蔡隱丘',\n '張翬',\n '談戭',\n '樊晃',\n '邢巨',\n '薛業',\n '袁瓘',\n '寇坦',\n '李休烈',\n '楊炎',\n '範朝',\n '張巡',\n '韋丹',\n '蕭昕',\n '楊諫',\n '趙良器',\n '郭良',\n '李收',\n '屈同仙',\n '豆盧複',\n '芮挺章',\n '陳季',\n '王邕',\n '李棲筠',\n '徐浩',\n '薛令之',\n '袁傪',\n '崔何',\n '王緯',\n '郭澹',\n '令狐峘',\n '蘇源明',\n '蘇渙',\n '韋建',\n '殷寅',\n '李岑2',\n '韋迢',\n '張濯',\n '姚倫',\n '張叔卿',\n '鄭丹',\n '張建封',\n '崔膺',\n '馮宿',\n '王武陵',\n '張佐',\n '閻濟美',\n '張少博',\n '周渭',\n '周存',\n '黎逢',\n '苗發',\n '衛象',\n '柳郴',\n '鄭概',\n '範燈',\n '樊珣',\n '劉蕃',\n '張松齡',\n '劉長川',\n '鄭審',\n '李幼卿',\n '羅讓',\n '李願',\n '蕭祜',\n '王良士',\n '顏粲',\n '張正元',\n '彭伉',\n '崔樞',\n '張嗣初',\n '許康佐',\n '楊于陵',\n '武少儀',\n '姚向',\n '溫會',\n '李敬伯',\n '郭遵',\n '許稷',\n '胡證',\n '席夔',\n '盧儲',\n '周元範',\n '王炎',\n '陳昌言',\n '李宣遠',\n '陳翥',\n '王播',\n '宋濟',\n '蘇郁',\n '蘇鬱',\n '於頔',\n '吳武陵',\n '封敖',\n '楊虞卿',\n '趙蕃',\n '唐扶',\n '侯冽',\n '李播',\n '滕倪',\n '劉虛白',\n '郭良驥',\n '柳泌',\n '朱沖和',\n '張光朝',\n '裴潾',\n ...]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('作者到整数转换表.json') as f:\n",
    "    j = json.load(f)\n",
    "    # print(j)\n",
    "    整数到作者转换表 = ['' for i in range(len(j))]\n",
    "    for (作者, 数字) in j.items():\n",
    "        整数到作者转换表[数字] = 作者\n",
    "整数到作者转换表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    },
    {
     "data": {
      "text/plain": "'白居易'"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_poet(num):\n",
    "    return 整数到作者转换表[num]\n",
    "a = train_y[2200]\n",
    "print(a.dtype)\n",
    "# print(a)\n",
    "# a[0]\n",
    "decode_poet(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "露冷風輕霽魄圓，高樓更在碧山巔。四溟水合疑無地，夜深獨與岩僧語，群動消聲舉世眠。\n"
     ]
    },
    {
     "data": {
      "text/plain": "'唐彥謙'"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = [x[0] for x in train_x]\n",
    "test_x = [x[0] for x in test_x]\n",
    "print(decode_poetry(test_x[0]))\n",
    "decode_poet(test_y[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整数数组必须在输入神经网络之前转换为张量。这种转换可以通过以下两种方式来完成：\n",
    "将数组转换为表示单词出现与否的由 0 和 1 组成的向量，类似于 one-hot 编码。例如，序列[3, 5]将转换为一个 10,000 维的向量，该向量除了索引为 3 和 5 的位置是 1 以外，其他都为 0。然后，将其作为网络的首层——一个可以处理浮点型向量数据的稠密层。不过，这种方法需要大量的内存，需要一个大小为 num_words * num_reviews 的矩阵。\n",
    "或者，我们可以填充数组来保证输入数据具有相同的长度，然后创建一个大小为 max_length * num_reviews 的整型张量。我们可以使用能够处理此形状数据的嵌入层作为网络中的第一层。\n",
    "在本教程中，我们将使用第二种方法。\n",
    "由于电影评论长度必须相同，我们将使用 pad_sequences 函数来使长度标准化："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "print(max(map(len, train_x)))\n",
    "print(max(map(len, test_x)))\n",
    "# 不妙，数据处理的时候应当限制为五言、七言、绝句、律诗"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "vocab_size = 7611\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_x,\n",
    "                                                        value=vocab_size,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=56)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_x,\n",
    "                                                       value=vocab_size,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=56)\n",
    "# 假入强行56，会怎么样？  TODO 可以改为4500"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "露冷風輕霽魄圓，高樓更在碧山巔。四溟水合疑無地，夜深獨與岩僧語，群動消聲舉世眠。\n"
     ]
    },
    {
     "data": {
      "text/plain": "(56, 56)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(decode_poetry([i for i in test_data[0] if i != vocab_size]))\n",
    "len(train_data[0]), len(train_data[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n"
     ]
    }
   ],
   "source": [
    "print(set(train_y))\n",
    "print(set(test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 16)          121792    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1600)              27200     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 100)               160100    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,092\n",
      "Trainable params: 309,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 输入形状是用于诗词的汉字数目（7611 词）\n",
    "vocab_size = 7611\n",
    "poets = 100\n",
    "\n",
    "model = keras.Sequential()\n",
    "# 第一维始终是batch的大小。\n",
    "model.add(keras.layers.Embedding(vocab_size+1, 16)) # 变成16个字\n",
    "# 官方解释：查找每个词索引的嵌入向量（embedding vector）\n",
    "# 嵌入向量是16维的。\n",
    "# 对于一系列batch的数据，把bx56 嵌入到b个 不知道多长的，每个单词变长16维向量的一个向量\n",
    "model.add(keras.layers.GlobalAveragePooling1D()) # 把变长的张量变长定长的？\n",
    "# 对于每一个 嵌入向量，每个单词16维，一句话不定长，直接把一句话的词向量求平均加起来。\n",
    "# model.add(keras.layers.Dense(256, activation='relu')) # （输出为）16个单元的全连接层。\n",
    "model.add(keras.layers.Dense(1600, activation='relu')) # （输出为）16个单元的全连接层。\n",
    "model.add(keras.layers.Dense(poets, activation='softmax')) #对上一层的结构dense为一个，然后sigmoid？\n",
    "\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.8877 - accuracy: 0.2899\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.8002 - accuracy: 0.3092\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.7110 - accuracy: 0.3285\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.6313 - accuracy: 0.3441\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.5514 - accuracy: 0.3654\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.4811 - accuracy: 0.3821\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.4107 - accuracy: 0.3975\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.3438 - accuracy: 0.4105\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.2820 - accuracy: 0.4220\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.2278 - accuracy: 0.4332\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.1693 - accuracy: 0.4500\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.1140 - accuracy: 0.4632\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 2.0593 - accuracy: 0.4788\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.9999 - accuracy: 0.4920\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.9466 - accuracy: 0.5053\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.8884 - accuracy: 0.5205\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.8346 - accuracy: 0.5348\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.7810 - accuracy: 0.5496\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.7299 - accuracy: 0.5622\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.6760 - accuracy: 0.5756\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.6290 - accuracy: 0.5862\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.5820 - accuracy: 0.5984\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.5350 - accuracy: 0.6120\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.4903 - accuracy: 0.6238\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.4472 - accuracy: 0.6332\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.4095 - accuracy: 0.6429\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.3681 - accuracy: 0.6528\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.3314 - accuracy: 0.6631\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.2949 - accuracy: 0.6717\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.2604 - accuracy: 0.6809\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.2249 - accuracy: 0.6912\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.1924 - accuracy: 0.6952\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.1606 - accuracy: 0.7067\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.1323 - accuracy: 0.7115\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.1012 - accuracy: 0.7201\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.0729 - accuracy: 0.7285\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.0494 - accuracy: 0.7345\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 1.0241 - accuracy: 0.7410\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.9960 - accuracy: 0.7473\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.9748 - accuracy: 0.7537\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.9528 - accuracy: 0.7597\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.9307 - accuracy: 0.7632\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.9073 - accuracy: 0.7691\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.8885 - accuracy: 0.7747\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.8680 - accuracy: 0.7795\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.8486 - accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.8267 - accuracy: 0.7924\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.8117 - accuracy: 0.7929\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 3s 3ms/step - loss: 0.7939 - accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.7763 - accuracy: 0.8050\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.7560 - accuracy: 0.8089\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 3s 3ms/step - loss: 0.7420 - accuracy: 0.8144\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 3s 4ms/step - loss: 0.7271 - accuracy: 0.8162\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 3s 3ms/step - loss: 0.7104 - accuracy: 0.8207\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6920 - accuracy: 0.8256\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6787 - accuracy: 0.8293\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6622 - accuracy: 0.8344\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6479 - accuracy: 0.8373\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6363 - accuracy: 0.8408\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6241 - accuracy: 0.8443\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.6085 - accuracy: 0.8479\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5964 - accuracy: 0.8512\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5816 - accuracy: 0.8546\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5701 - accuracy: 0.8568\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5590 - accuracy: 0.8612\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.8652\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5335 - accuracy: 0.8689\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5225 - accuracy: 0.8717\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5091 - accuracy: 0.8744\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.5003 - accuracy: 0.8765\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4873 - accuracy: 0.8811\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4779 - accuracy: 0.8820\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4658 - accuracy: 0.8865\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4542 - accuracy: 0.8887\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4483 - accuracy: 0.8911\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4370 - accuracy: 0.8936\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4259 - accuracy: 0.8965\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4191 - accuracy: 0.8987\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.4038 - accuracy: 0.9056\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3995 - accuracy: 0.9038\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3899 - accuracy: 0.9063\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3807 - accuracy: 0.9095\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3747 - accuracy: 0.9105\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3665 - accuracy: 0.9124\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3539 - accuracy: 0.9158\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3448 - accuracy: 0.9191\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3362 - accuracy: 0.9200\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 3s 3ms/step - loss: 0.3297 - accuracy: 0.9227\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3241 - accuracy: 0.9230\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3157 - accuracy: 0.9255\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3096 - accuracy: 0.9288\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.3004 - accuracy: 0.9307\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2931 - accuracy: 0.9327\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2888 - accuracy: 0.9332\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 3s 4ms/step - loss: 0.2804 - accuracy: 0.9350\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2690 - accuracy: 0.9403\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2676 - accuracy: 0.9391\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2636 - accuracy: 0.9401\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2556 - accuracy: 0.9414\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 2s 3ms/step - loss: 0.2430 - accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_y, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 - 1s - loss: 19.9505 - accuracy: 0.1633 - 676ms/epoch - 4ms/step\n",
      "[19.950529098510742, 0.16331657767295837]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,  test_y, verbose=2)\n",
    "print(results)  # 好垃圾，0.16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}