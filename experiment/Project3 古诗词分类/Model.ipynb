{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 下面开始机器学习\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据集来咯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_x', 'test_x', 'train_y', 'test_y']\n",
      "(23877, 1)\n"
     ]
    }
   ],
   "source": [
    "with np.load('唐诗处理后数据集.npz', allow_pickle=True) as data:\n",
    "    print(data.files)\n",
    "    train_x,test_x,train_y,test_y = data['train_x'], data['test_x'], data['train_y'], data['test_y']\n",
    "print(train_x.shape)\n",
    "# train_x.astype(int)\n",
    "# train_x.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解读回去"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "['，',\n '。',\n '十',\n '卷',\n '百',\n '一',\n '不',\n '人',\n '三',\n '二',\n '四',\n '五',\n '山',\n '日',\n '六',\n '無',\n '八',\n '七',\n '風',\n '中',\n '上',\n '雲',\n '有',\n '九',\n '春',\n '白',\n '天',\n '何',\n '來',\n '月',\n '花',\n '水',\n '時',\n '相',\n '長',\n '君',\n '歸',\n '秋',\n '年',\n '為',\n '生',\n '自',\n '行',\n '江',\n '見',\n '夜',\n '心',\n '知',\n '李',\n '如',\n '此',\n '得',\n '清',\n '下',\n '高',\n '去',\n '南',\n '空',\n '明',\n '在',\n '子',\n '門',\n '事',\n '客',\n '送',\n '道',\n '未',\n '處',\n '居',\n '東',\n '別',\n '金',\n '歌',\n '王',\n '多',\n '青',\n '是',\n '寒',\n '玉',\n '城',\n '雨',\n '遠',\n '朝',\n '家',\n '落',\n '新',\n '出',\n '今',\n '與',\n '西',\n '應',\n '寄',\n '陽',\n '思',\n '千',\n '前',\n '聲',\n '入',\n '書',\n '路',\n '萬',\n '馬',\n '望',\n '草',\n '我',\n '同',\n '飛',\n '深',\n '樹',\n '和',\n '流',\n '開',\n '將',\n '盡',\n '酒',\n '獨',\n '還',\n '已',\n '聞',\n '回',\n '成',\n '地',\n '煙',\n '光',\n '詩',\n '公',\n '重',\n '可',\n '石',\n '誰',\n '色',\n '林',\n '欲',\n '從',\n '雪',\n '古',\n '作',\n '州',\n '方',\n '向',\n '更',\n '之',\n '：',\n '海',\n '首',\n '樓',\n '看',\n '舊',\n '老',\n '易',\n '張',\n '情',\n '滿',\n '身',\n '然',\n '後',\n '愁',\n '香',\n '名',\n '過',\n '言',\n '黃',\n '衣',\n '能',\n '外',\n '遊',\n '頭',\n '平',\n '起',\n '樂',\n '難',\n '塵',\n '龍',\n '曲',\n '裏',\n '大',\n '安',\n '莫',\n '紅',\n '北',\n '華',\n '松',\n '仙',\n '閑',\n '分',\n '故',\n '複',\n '到',\n '似',\n '初',\n '懷',\n '晚',\n '少',\n '宮',\n '葉',\n '猶',\n '離',\n '當',\n '零',\n '竹',\n '氣',\n '意',\n '題',\n '鳥',\n '柳',\n '贈',\n '因',\n '間',\n '劉',\n '非',\n '文',\n '辭',\n '亦',\n '吟',\n '元',\n '國',\n '邊',\n '暮',\n '所',\n '幾',\n '池',\n '夢',\n '留',\n '漢',\n '孤',\n '餘',\n '逢',\n '問',\n '溪',\n '寺',\n '庭',\n '隱',\n '杜',\n '里',\n '士',\n '—',\n '陰',\n '河',\n '醉',\n '野',\n '隨',\n '物',\n '神',\n '關',\n '世',\n '登',\n '歲',\n '枝',\n '幽',\n '臨',\n '微',\n '泉',\n '坐',\n '露',\n '使',\n '若',\n '終',\n '發',\n '期',\n '小',\n '宿',\n '休',\n '經',\n '鄉',\n '芳',\n '好',\n '霜',\n '台',\n '輕',\n '憶',\n '以',\n '至',\n '早',\n '碧',\n '連',\n '陵',\n '綠',\n '半',\n '波',\n '鶴',\n '太',\n '郎',\n '才',\n '官',\n '亭',\n '先',\n '共',\n '正',\n '對',\n '合',\n '者',\n '近',\n '尋',\n '曾',\n '吹',\n '照',\n '舟',\n '豈',\n '兩',\n '曉',\n '夕',\n '常',\n '影',\n '羅',\n '翠',\n '遙',\n '楚',\n '雙',\n '苦',\n '須',\n '峰',\n '驚',\n '主',\n '園',\n '沙',\n '殘',\n '斷',\n '師',\n '僧',\n '楊',\n '動',\n '靜',\n '悲',\n '木',\n '垂',\n '景',\n '興',\n '卻',\n '川',\n '病',\n '恩',\n '紫',\n '德',\n '吳',\n '奉',\n '章',\n '堂',\n '湖',\n '靈',\n '又',\n '語',\n '絕',\n '久',\n '依',\n '真',\n '鳳',\n '蕭',\n '女',\n '鳴',\n '浮',\n '笑',\n '聽',\n '吾',\n '魚',\n '蒼',\n '皇',\n '忽',\n '通',\n '秦',\n '尚',\n '唯',\n '府',\n '車',\n '丹',\n '甫',\n '星',\n '憐',\n '傳',\n '愛',\n '詠',\n '齊',\n '群',\n '淚',\n '侍',\n '郊',\n '虛',\n '田',\n '帝',\n '游',\n '數',\n '夫',\n '寂',\n '聖',\n '許',\n '昔',\n '會',\n '且',\n '閣',\n '雁',\n '舞',\n '句',\n '只',\n '令',\n '轉',\n '堪',\n '節',\n '洞',\n '散',\n '其',\n '恨',\n '武',\n '軍',\n '往',\n '謝',\n '窮',\n '親',\n '疏',\n '征',\n '蘭',\n '朱',\n '直',\n '胡',\n '說',\n '涼',\n '悠',\n '亂',\n '用',\n '感',\n '始',\n '度',\n '容',\n '桃',\n '火',\n '洛',\n '信',\n '遲',\n '韋',\n '覺',\n '窗',\n '韓',\n '觀',\n '待',\n '賢',\n '足',\n '禦',\n '燕',\n '手',\n '畫',\n '傷',\n '霞',\n '宴',\n '晴',\n '死',\n '喜',\n '勝',\n '學',\n '功',\n '琴',\n '劍',\n '皆',\n '暗',\n '酬',\n '移',\n '顧',\n '即',\n '雖',\n '步',\n '陳',\n '及',\n '帶',\n '識',\n '崔',\n '結',\n '立',\n '珠',\n '塞',\n '岩',\n '顏',\n '羽',\n '逐',\n '周',\n '都',\n '卿',\n '臥',\n '幹',\n '願',\n '歡',\n '徒',\n '岸',\n '食',\n '桂',\n '兒',\n '命',\n '廟',\n '斜',\n '司',\n '隔',\n '友',\n '含',\n '夏',\n '鏡',\n '京',\n '繞',\n '橫',\n '遺',\n '解',\n '殿',\n '湘',\n '棲',\n '孟',\n '倚',\n '盧',\n '禪',\n '己',\n '絲',\n '雜',\n '浪',\n '憂',\n '兵',\n '美',\n '化',\n '玄',\n '舍',\n '於',\n '杯',\n '乘',\n '諸',\n '貴',\n '荒',\n '陸',\n '跡',\n '定',\n '交',\n '薄',\n '疑',\n '爾',\n '徐',\n '本',\n '闕',\n '藥',\n '越',\n '異',\n '飲',\n '商',\n '求',\n '兼',\n '便',\n '惜',\n '拂',\n '爭',\n '騎',\n '臣',\n '鐘',\n '賦',\n '詞',\n '口',\n '忘',\n '錦',\n '翻',\n '勞',\n '燈',\n '頻',\n '兮',\n '端',\n '郡',\n '著',\n '鄭',\n '眼',\n '啼',\n '飄',\n '守',\n '素',\n '念',\n '蒙',\n '第',\n '迎',\n '孫',\n '映',\n '侯',\n '猿',\n '徑',\n '力',\n '榮',\n '音',\n '苔',\n '任',\n '沉',\n '錢',\n '錫',\n '鄰',\n '遇',\n '參',\n '韻',\n '字',\n '史',\n '圖',\n '赴',\n '良',\n '教',\n '梁',\n '惟',\n '極',\n '橋',\n '他',\n '凝',\n '院',\n '船',\n '冷',\n '戰',\n '閒',\n '軒',\n '由',\n '引',\n '禮',\n '弦',\n '永',\n '稀',\n '衰',\n '條',\n '報',\n '折',\n '蓮',\n '悵',\n '搖',\n '住',\n '載',\n '幸',\n '況',\n '罷',\n '目',\n '村',\n '暖',\n '貧',\n '制',\n '細',\n '息',\n '歎',\n '壁',\n '嶺',\n '偏',\n '原',\n '裴',\n '蓬',\n '怨',\n '滄',\n '但',\n '鼓',\n '臺',\n '齋',\n '想',\n '蜀',\n '建',\n '掩',\n '緣',\n '偶',\n '魂',\n '持',\n '內',\n '論',\n '彩',\n '取',\n '漸',\n '接',\n '禹',\n '宜',\n '眠',\n '梅',\n '宅',\n '暫',\n '舉',\n '洲',\n '變',\n '寶',\n '沈',\n '低',\n '鬢',\n '破',\n '紛',\n '佳',\n '戶',\n '訪',\n '宗',\n '釣',\n '面',\n '懸',\n '房',\n '冰',\n '穀',\n '皎',\n '簾',\n '俗',\n '尊',\n '鶯',\n '泛',\n '封',\n '精',\n '館',\n '片',\n '失',\n '晨',\n '骨',\n '傾',\n '島',\n '業',\n '帆',\n '雞',\n '虎',\n '曹',\n '井',\n '獻',\n '浦',\n '攜',\n '弟',\n '代',\n '傍',\n '吏',\n '枕',\n '鴻',\n '龜',\n '秀',\n '既',\n '丘',\n '土',\n '漁',\n '昏',\n '室',\n '迷',\n '盤',\n '賞',\n '賈',\n '唐',\n '理',\n '必',\n '荊',\n '伴',\n '泥',\n '蟬',\n '承',\n '翁',\n '眉',\n '冥',\n '旅',\n '揚',\n '積',\n '詳',\n '渡',\n '根',\n '茲',\n '冠',\n '氏',\n '源',\n '冬',\n '采',\n '盛',\n '陶',\n '再',\n '籍',\n '仍',\n '機',\n '賓',\n '縣',\n '渾',\n '收',\n '管',\n '蘇',\n '敢',\n '雄',\n '浩',\n '鬥',\n '床',\n '眾',\n '志',\n '英',\n '途',\n '階',\n '全',\n '急',\n '薛',\n '狂',\n '溫',\n '牧',\n '嚴',\n '拜',\n '趙',\n '藏',\n '殊',\n '指',\n '稱',\n '那',\n '最',\n '繁',\n '腸',\n '茫',\n '霧',\n '適',\n '殷',\n '種',\n '融',\n '旗',\n '賀',\n '戎',\n '廣',\n '性',\n '席',\n '竟',\n '比',\n '衡',\n '每',\n '遂',\n '嘉',\n '形',\n '涯',\n '象',\n '閉',\n '哀',\n '烏',\n '修',\n '侵',\n '旌',\n '乃',\n '慚',\n '荷',\n '昭',\n '寥',\n '維',\n '澤',\n '昨',\n '于',\n '列',\n '牛',\n '尺',\n '燭',\n '髮',\n '恐',\n '銀',\n '各',\n '攀',\n '次',\n '津',\n '戴',\n '抱',\n '憑',\n '答',\n '省',\n '被',\n '姚',\n '苑',\n '危',\n '淒',\n '投',\n '桑',\n '筆',\n '莊',\n '曙',\n '郭',\n '惆',\n '調',\n '放',\n '哭',\n '把',\n '集',\n '寧',\n '宵',\n '角',\n '童',\n '貫',\n '喧',\n '屋',\n '降',\n '負',\n '法',\n '計',\n '營',\n '甘',\n '銷',\n '遍',\n '淩',\n '塘',\n '禁',\n '叢',\n '岑',\n '嗟',\n '消',\n '並',\n '夷',\n '縱',\n '濕',\n '谷',\n '輪',\n '昌',\n '菊',\n '駕',\n '招',\n '篇',\n '瑤',\n '驛',\n '毛',\n '沒',\n '淮',\n '潭',\n '廬',\n '鸞',\n '短',\n '兄',\n '嶽',\n '誠',\n '走',\n '幕',\n '漏',\n '斯',\n '點',\n '淺',\n '而',\n '員',\n '勢',\n '宣',\n '程',\n '潮',\n '仁',\n '赤',\n '催',\n '茅',\n '奇',\n '盈',\n '勤',\n '輿',\n '晝',\n '蓋',\n '筵',\n '戲',\n '繡',\n '巴',\n '達',\n '陪',\n '枯',\n '豔',\n '弄',\n '澗',\n '愈',\n '霄',\n '雷',\n '綺',\n '渚',\n '粉',\n '禽',\n '陌',\n '漫',\n '慶',\n '沾',\n '存',\n '瓊',\n '驅',\n '巢',\n '掃',\n '強',\n '肯',\n '淨',\n '妾',\n '妝',\n '峽',\n '叔',\n '俱',\n '籠',\n '披',\n '義',\n '潛',\n '棹',\n '丞',\n '利',\n '壯',\n '益',\n '燒',\n '延',\n '升',\n '避',\n '疾',\n '輝',\n '迢',\n '佩',\n '響',\n '羨',\n '宋',\n '試',\n '爐',\n '遣',\n '銜',\n '□',\n '稹',\n '桐',\n '呈',\n '借',\n '掛',\n '壽',\n '襟',\n '背',\n '奏',\n '權',\n '詔',\n '擬',\n '境',\n '滴',\n '底',\n '也',\n '服',\n '滅',\n '唱',\n '聊',\n '圓',\n '除',\n '威',\n ...]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('中文到整数转换表.json') as f:\n",
    "    j = json.load(f)\n",
    "    # print(j)\n",
    "    整数到中文转换表 = ['' for i in range(len(j))]\n",
    "    for (汉字, 数字) in j.items():\n",
    "        整数到中文转换表[数字] = 汉字\n",
    "整数到中文转换表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": "'朱藤朱藤，溫如紅玉，直如朱繩。自我得爾以為杖，中途不進，部曲多回。唯此朱藤，實隨我來。瘴癘之鄉，或水或陸，自北徂南。泥黏雪滑，足力不堪。吾本兩足，吾與爾披雲撥水，環山繞野。二年蹋遍匡廬間，'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.csdn.net/gavin_john/article/details/50717695 中括号取item运算符重载\n",
    "def decode_poetry(num_array):\n",
    "    return \"\".join(map(整数到中文转换表.__getitem__, num_array))\n",
    "a = train_x[2200]\n",
    "print(a.dtype)\n",
    "# print(a)\n",
    "# a[0]\n",
    "decode_poetry(a[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "['白居易',\n '杜甫',\n '李白',\n '齊己',\n '劉禹錫',\n '元稹',\n '李商隱',\n '貫休',\n '韋應物',\n '陸龜蒙',\n '劉長卿',\n '許渾',\n '皎然',\n '杜牧',\n '羅隱',\n '張籍',\n '姚合',\n '錢起',\n '賈島',\n '孟郊',\n '王建',\n '岑參',\n '韓愈',\n '張祜',\n '皮日休',\n '王維',\n '溫庭筠',\n '權德輿',\n '方幹',\n '韋莊',\n '杜荀鶴',\n '盧綸',\n '韓偓',\n '張說',\n '戴叔倫',\n '李中',\n '吳融',\n '李端',\n '薛能',\n '孟浩然',\n '趙嘏',\n '徐鉉',\n '徐夤',\n '皇甫冉',\n '李群玉',\n '李賀',\n '顧況',\n '司空圖',\n '高適',\n '李嶠',\n '李頻',\n '鄭穀',\n '黃滔',\n '施肩吾',\n '周曇',\n '張九齡',\n '宋之問',\n '武元衡',\n '鮑溶',\n '耿湋',\n '李益',\n '儲光羲',\n '司空曙',\n '沈佺期',\n '王昌齡',\n '柳宗元',\n '馬戴',\n '朱慶餘',\n '張喬',\n '李洞',\n '唐彥謙',\n '韓翃',\n '胡曾',\n '楊巨源',\n '曹松',\n '羅鄴',\n '李鹹用',\n '劉得仁',\n '許棠',\n '李德裕',\n '李嘉佑',\n '李頎',\n '李紳',\n '駱賓王',\n '雍陶',\n '戎昱',\n '鄭谷',\n '劉商',\n '陳陶',\n '盧照鄰',\n '李涉',\n '呂岩',\n '蘇頲',\n '曹鄴',\n '呂溫',\n '劉滄',\n '張蠙',\n '崔塗',\n '項斯',\n '無可',\n '羊士諤',\n '周賀',\n '盧仝',\n '薛逢',\n '徐凝',\n '元結',\n '陳子昂',\n '李世民',\n '李建勳',\n '獨孤及',\n '王勃',\n '歐陽詹',\n '殷堯藩',\n '李山甫',\n '薛濤',\n '吳筠',\n '孫元晏',\n '劉駕',\n '劉兼',\n '郎士元',\n '顧非熊',\n '劉言史',\n '李郢',\n '嚴維',\n '章孝標',\n '崔道融',\n '王貞白',\n '李隆基',\n '喻鳧',\n '陳羽',\n '牟融',\n '楊衡',\n '孫逖',\n '汪遵',\n '裴夷直',\n '王周',\n '崔國輔',\n '常建',\n '令狐楚',\n '裴說',\n '於鵠',\n '于武陵',\n '段成式',\n '皇甫曾',\n '張繼',\n '高駢',\n '魚玄機',\n '武則天',\n '包佶',\n '崔顥',\n '崔峒',\n '王績',\n '李乂',\n '聶夷中',\n '賈至',\n '靈一',\n '杜審言',\n '曹唐',\n '張謂',\n '竇鞏',\n '譚用之',\n '楊凝',\n '儲嗣宗',\n '司馬紮',\n '李煜',\n '於濆',\n '秦韜玉',\n '虞世南',\n '秦系',\n '徐彥伯',\n '祖詠',\n '魏征',\n '孫光憲',\n '陸暢',\n '李遠',\n '李咸用',\n '唐求',\n '褚亮',\n '李昌符',\n '崔湜',\n '劉希夷',\n '高蟾',\n '楊炯',\n '姚鵠',\n '邵謁',\n '林寬',\n '尚顏',\n '李適',\n '王涯',\n '馮延巳',\n '張泌',\n '雍裕之',\n '翁承贊',\n '孟貫',\n '張仲素',\n '顏真卿',\n '熊孺登',\n '崔櫓',\n '裴度',\n '劉方平',\n '李百藥',\n '裴迪',\n '鄭巢',\n '盧肇',\n '來鵠',\n '蘇拯',\n '杜光庭',\n '許敬宗',\n '殷文圭',\n '劉憲',\n '朱放',\n '張南史',\n '劉叉',\n '劉威',\n '修睦',\n '歐陽炯',\n '盧象',\n '綦毋潛',\n '竇常',\n '沈亞之',\n '章碣',\n '鄭愔',\n '子蘭',\n '韓琮',\n '和凝',\n '周樸',\n '竇群',\n '朱灣',\n '於鄴',\n '喬知之',\n '長孫佐輔',\n '孫魴',\n '趙彥昭',\n '周繇',\n '伍喬',\n '清江',\n '毛文錫',\n '楊師道',\n '孟雲卿',\n '賀知章',\n '楊淩',\n '竇牟',\n '周朴',\n '陸希聲',\n '上官儀',\n '竇庠',\n '許彬',\n '成彥雄',\n '董思恭',\n '皇甫松',\n '蕭穎士',\n '包何',\n '楊憑',\n '李九齡',\n '胡宿',\n '李冶',\n '沈彬',\n '陶翰',\n '張子容',\n '郭震',\n '于鵠',\n '孟遲',\n '喻坦之',\n '任翻',\n '靈澈',\n '劉昚虛',\n '王翰',\n '王轂',\n '李珣',\n '崔融1',\n '趙冬曦',\n '張又新',\n '王初',\n '顧夐',\n '法振',\n '徐氏',\n '武平一',\n '梁鍠',\n '劉複',\n '朱景玄',\n '張賁',\n '廣宣',\n '棲白',\n '翁綬',\n '李華',\n '閻朝隱',\n '牛嶠',\n '蘇味道',\n '崔曙',\n '暢當',\n '張碧',\n '鄭畋',\n '褚載',\n '王仁裕',\n '劉昭禹',\n '蔣吉',\n '鄭遨',\n '虛中',\n '薛稷',\n '盧延讓',\n '崔日用',\n '莊南傑',\n '陳子良',\n '盧僎',\n '丘為',\n '李紓',\n '薛據',\n '王季友1',\n '丘丹',\n '盧殷',\n '楊發',\n '翁洮',\n '毛熙震',\n '丁仙芝',\n '馬懷素',\n '張諤',\n '徐安貞',\n '柳中庸',\n '薛存誠',\n '韋處厚',\n '陳去疾',\n '蔣防',\n '陳標',\n '薛瑩',\n '吳仁璧',\n '孔德紹',\n '楊夔',\n '護國',\n '棲蟾',\n '尹鶚',\n '徐堅',\n '于濆',\n '李廓',\n '鄭錫',\n '姚系',\n '王灣',\n '冷朝陽',\n '崔玨',\n '于鄴',\n '熊皎',\n '左偃',\n '水神',\n '袁暉',\n '王睿',\n '韋元旦',\n '盧鴻一',\n '常袞',\n '竇叔向',\n '李赤',\n '費冠卿',\n '韋蟾',\n '蔣貽恭',\n '可止',\n '李逢吉',\n '李約',\n '王縉',\n '萬楚',\n '李義府',\n '陳叔達',\n '武三思',\n '蕭至忠',\n '楊汝士',\n '崔涯',\n '歐陽袞',\n '李昭象',\n '盧士衡',\n '江為',\n '吳商浩',\n '處默',\n '李治',\n '姚崇',\n '孟簡',\n '韋承慶',\n '郎大家宋氏',\n '張文琮',\n '吳少微',\n '薛曜',\n '盧藏用',\n '包融',\n '陳潤',\n '鮑防',\n '張登',\n '李敬方',\n '顧雲',\n '孟賓於',\n '韓溉',\n '伊用昌',\n '薛昭蘊',\n '魏承班',\n '李顯',\n '李忱',\n '上官昭容',\n '鄭絪',\n '張袞',\n '張循之',\n '王無競',\n '王適',\n '厲玄',\n '薛奇童',\n '王諲',\n '張潮',\n '崔液',\n '張志和',\n '劉孝孫',\n '孔紹安',\n '宗楚客',\n '于季子',\n '韋嗣立',\n '賀朝',\n '蔣冽',\n '朱長文',\n '于良史',\n '陳翊',\n '崔元翰',\n '麹信陵',\n '李翱',\n '白行簡',\n '舒元輿',\n '霍總',\n '王駕',\n '錢珝',\n '劉象',\n '徐仲雅',\n '廖融',\n '史鳳',\n '閻選',\n '李昂1',\n '徐賢妃',\n '李衍',\n '賈曾',\n '牛僧孺',\n '李舒',\n '鄭世翼',\n '王之渙',\n '李暇',\n '張柬之',\n '李康成',\n '張彪',\n '田娥',\n '任希古',\n '宋璟',\n '張均',\n '岑羲',\n '胡皓',\n '張旭',\n '劉灣',\n '沈頌',\n '閻防',\n '嚴武',\n '章八元',\n '陳存',\n '崔護',\n '王起',\n '林滋',\n '李宣古',\n '鄭損',\n '李沇',\n '鄭准',\n '王岩',\n '馮道',\n '陳貺',\n '牛希濟',\n '詹敦仁',\n '王元',\n '張夫人',\n '張窈窕',\n '義淨',\n '歸仁',\n '可朋',\n '慕幽',\n '許堅2',\n '蜀宮群仙',\n '李貞白',\n '李璟',\n '段文昌',\n '張易之',\n '郭元振',\n '袁朗',\n '李嶷',\n '陸長源',\n '庾抱',\n '劉禕之',\n '徐晶',\n '李泌',\n '許景先',\n '蔡希寂',\n '殷遙',\n '王泠然',\n '崔興宗',\n '徐九皋',\n '閻寬',\n '于邵',\n '沈千運',\n '呂渭',\n '崔備',\n '徐敞',\n '張聿',\n '李正封',\n '鄭澣',\n '李程',\n '楊嗣複',\n '沈傳師',\n '周匡物',\n '袁不約',\n '楊乘',\n '趙璜',\n '潘鹹',\n '鄭綮',\n '歐陽玭',\n '公乘億',\n '盧汝弼',\n '楊凝式',\n '黃損',\n '韓熙載',\n '潘佑',\n '廖匡圖',\n '徐鍇',\n '許堅1',\n '湯悅',\n '吳越人',\n '李濤',\n '盧休',\n '李範',\n '晁采',\n '姚月華',\n '梁瓊',\n '趙鸞鸞',\n '慧淨',\n '隱巒',\n '雲台峰女仙',\n '陳季卿',\n '權龍褒',\n '文丙',\n '鮑君徽',\n '韓休',\n '郭子儀',\n '李回',\n '員半千',\n '許孟容',\n '崔邠',\n '趙光逢',\n '紀唐夫',\n '王偃',\n '辛弘智',\n '張紘',\n '韋渠牟',\n '岑文本',\n '陸敬',\n '楊浚',\n '劉允濟',\n '韓仲宣',\n '高瑾',\n '崔泰之',\n '魏知古',\n '王琚',\n '李迥秀',\n '趙彥伯',\n '源幹曜',\n '裴漼',\n '韋述',\n '劉庭琦',\n '張嘉貞',\n '席豫',\n '沈如筠',\n '李邕',\n '萬齊融',\n '蔣維翰',\n '孫昌胤',\n '張鼎',\n '馮著',\n '蔣渙',\n '元季川',\n '陸贄',\n '王烈',\n '奚賈',\n '謝良輔',\n '劉迥',\n '皇甫澈',\n '李吉甫',\n '李觀',\n '李絳',\n '姚康',\n '馬異',\n '裴次元',\n '王魯複',\n '李渤',\n '柳公權',\n '張蕭遠',\n '何希堯',\n '柳棠',\n '祝元膺',\n '王鐸',\n '李玖',\n '莫宣卿',\n '鄭愚',\n '袁郊',\n '蕭遘',\n '袁皓',\n '鄭仁表',\n '鄭璧',\n '溫憲',\n '孫偓',\n '路德延',\n '胡令能',\n '孫棨',\n '張為',\n '劉斌',\n '羅紹威',\n '宋齊丘',\n '廖凝',\n '李家明',\n '翁宏',\n '劉乙',\n '胡玢',\n '狄煥',\n '楊希道',\n '鄭鏦',\n '紇幹著',\n '周濆',\n '馬逢',\n '吉師老',\n '姚揆',\n '易思',\n '賈彥璋',\n '韓常侍',\n '陳甫',\n '卞震',\n '趙氏2',\n '薛馧',\n '張文姬',\n '步非煙',\n '孟氏',\n '崔萱',\n '崔仲容',\n '慧宣',\n '善生',\n '卿雲',\n '馬湘',\n '張辭',\n '沈廷瑞',\n '卓英英',\n '張元一',\n '李存勖',\n '鹿虔扆',\n '李亨',\n '錢鏐',\n '盧從願',\n '蔡孚',\n '盧懷慎',\n '劉晏',\n '鄭餘慶',\n '蕭仿',\n '馮伉',\n '賈馳',\n '鄭渥',\n '東方虯',\n '朱光弼',\n '杜頠',\n '齊浣',\n '張若虛',\n '李希仲',\n '賀蘭進明',\n '常理',\n '李景伯',\n '盧貞',\n '謝偃',\n '長孫無忌',\n '杜淹',\n '崔善為',\n '歐陽詢',\n '元萬頃',\n '陳元光',\n '崔知賢',\n '陳嘉言',\n '張敬忠',\n '張昌宗',\n '喬備',\n '尹懋',\n '李崇嗣',\n '韋安石',\n '李元紘',\n '王丘',\n '周瑀',\n '孫處玄',\n '徐延壽',\n '李憕',\n '李昂2',\n '李林甫',\n '陳希烈',\n '宋昱',\n '崔翹',\n '陸海',\n '沈宇',\n '張萬頃',\n '樓穎',\n '劉太真',\n '褚朝陽',\n '畢耀',\n '趙征明',\n '任華',\n '韓滉',\n '韋夏卿',\n '張眾甫',\n '丁澤',\n '王表',\n '何兆',\n '陸羽',\n '鄭常',\n '竇參',\n '韋皋',\n '崔子向',\n '柳公綽',\n '林藻',\n '張薦',\n '潘孟陽',\n '崔立之',\n '範傳正',\n '張賈',\n '張文規',\n '張匯',\n '陳通方',\n '皇甫湜',\n '盧拱',\n '劉猛',\n '葉季良',\n '湛賁',\n '周弘亮',\n '張仲方',\n '崔玄亮',\n '符載',\n '孫叔向',\n '劉皂',\n '林傑',\n '蔡京',\n '楊敬之',\n '陳至',\n '鄭還古',\n '朱晝',\n '滕邁',\n '李餘',\n '白敏中',\n '常楚老',\n '平曾',\n '魏扶',\n '楊收',\n '鄭史',\n '元晦',\n '黃頗',\n '劉綺莊',\n '楊牢',\n '潘緯',\n '武瓘',\n '李騭',\n '張孜',\n '趙鴻',\n '李縠',\n '顏萱',\n '顧在鎔',\n '王渙',\n '戴司顏',\n '孫合',\n '李琪',\n '盧頻',\n '鄭良士',\n '伍唐珪',\n '陳光',\n '捧劍僕',\n '黃巢',\n '羅袞',\n '鐘謨',\n '王感化',\n '馮涓',\n '楊玢',\n '詹琲',\n '張立',\n '蘇廣文',\n '尉遲匡',\n '繆島雲',\n '夏寶松',\n '庸仁傑',\n '李堯夫',\n '段義宗',\n '李舜弦',\n '王韞秀',\n '孫氏',\n '程長文',\n '崔鶯鶯',\n '劉雲',\n '張琰',\n '劉媛',\n '劉瑤',\n '廉氏',\n '關盼盼',\n '王福娘',\n '徐月英',\n '元淳',\n '寒山',\n '景雲',\n '法照',\n '知玄',\n '澹交',\n '若虛',\n '曇域',\n '幹康',\n '惟審',\n '許宣平',\n '李夢符',\n '張白',\n '眉娘',\n '上元夫人',\n '滕傳胤',\n '湘中蛟女',\n '龍女',\n '何光遠',\n '韋璜',\n '西施',\n '王軒',\n '劉行敏',\n '裴諝',\n '徐昌圖',\n '李旦',\n '李賢',\n '孟昶',\n '韓思複',\n '劉晃',\n '王晙',\n '崔玄童',\n '何鸞',\n '蔣挺',\n '源光裕',\n '姜皎',\n '薑晞',\n '夏侯孜',\n '張齊賢',\n '鄭善玉',\n '胡雄',\n '祝欽明',\n '陳京',\n '歸登',\n '杜羔',\n '張昭',\n '劉氏雲',\n '竇威',\n '歐陽瑾',\n '趙微明',\n '梁獻',\n '顧朝陽',\n '梁氏瓊',\n '吳燭',\n '張修之',\n '裴交泰',\n '嚴識玄',\n '張烜',\n '王沈',\n '柯崇',\n '鄒紹先',\n '虞羽客',\n '張熾',\n '王訓',\n '李章',\n '滕潛',\n '王珪',\n '杜正倫',\n '崔信明',\n '馬周',\n '張文恭',\n '李敬玄',\n '楊思玄',\n '杜易簡',\n '趙謙光',\n '張鷟',\n '魏元忠',\n '李懷遠',\n '蘇瑰',\n '高正臣',\n '高球',\n '弓嗣初',\n '長孫正隱',\n '周彥暉',\n '高嶠',\n '周思鈞',\n '崔日知',\n '楊廉',\n '張錫',\n '解琬',\n '蕭嵩',\n '陸堅',\n '李適之',\n '鄭繇',\n '蘇晉',\n '王光庭',\n '裴耀卿',\n '宋鼎',\n '張宣明',\n '蔡隱丘',\n '張翬',\n '談戭',\n '樊晃',\n '邢巨',\n '薛業',\n '袁瓘',\n '寇坦',\n '李休烈',\n '楊炎',\n '範朝',\n '張巡',\n '韋丹',\n '蕭昕',\n '楊諫',\n '趙良器',\n '郭良',\n '李收',\n '屈同仙',\n '豆盧複',\n '芮挺章',\n '陳季',\n '王邕',\n '李棲筠',\n '徐浩',\n '薛令之',\n '袁傪',\n '崔何',\n '王緯',\n '郭澹',\n '令狐峘',\n '蘇源明',\n '蘇渙',\n '韋建',\n '殷寅',\n '李岑2',\n '韋迢',\n '張濯',\n '姚倫',\n '張叔卿',\n '鄭丹',\n '張建封',\n '崔膺',\n '馮宿',\n '王武陵',\n '張佐',\n '閻濟美',\n '張少博',\n '周渭',\n '周存',\n '黎逢',\n '苗發',\n '衛象',\n '柳郴',\n '鄭概',\n '範燈',\n '樊珣',\n '劉蕃',\n '張松齡',\n '劉長川',\n '鄭審',\n '李幼卿',\n '羅讓',\n '李願',\n '蕭祜',\n '王良士',\n '顏粲',\n '張正元',\n '彭伉',\n '崔樞',\n '張嗣初',\n '許康佐',\n '楊于陵',\n '武少儀',\n '姚向',\n '溫會',\n '李敬伯',\n '郭遵',\n '許稷',\n '胡證',\n '席夔',\n '盧儲',\n '周元範',\n '王炎',\n '陳昌言',\n '李宣遠',\n '陳翥',\n '王播',\n '宋濟',\n '蘇郁',\n '蘇鬱',\n '於頔',\n '吳武陵',\n '封敖',\n '楊虞卿',\n '趙蕃',\n '唐扶',\n '侯冽',\n '李播',\n '滕倪',\n '劉虛白',\n '郭良驥',\n '柳泌',\n '朱沖和',\n '張光朝',\n '裴潾',\n ...]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('作者到整数转换表.json') as f:\n",
    "    j = json.load(f)\n",
    "    # print(j)\n",
    "    整数到作者转换表 = ['' for i in range(len(j))]\n",
    "    for (作者, 数字) in j.items():\n",
    "        整数到作者转换表[数字] = 作者\n",
    "整数到作者转换表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    },
    {
     "data": {
      "text/plain": "'白居易'"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_poet(num):\n",
    "    return 整数到作者转换表[num]\n",
    "a = train_y[2200]\n",
    "print(a.dtype)\n",
    "# print(a)\n",
    "# a[0]\n",
    "decode_poet(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "露冷風輕霽魄圓，高樓更在碧山巔。四溟水合疑無地，夜深獨與岩僧語，群動消聲舉世眠。\n"
     ]
    },
    {
     "data": {
      "text/plain": "'唐彥謙'"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = [x[0] for x in train_x]\n",
    "test_x = [x[0] for x in test_x]\n",
    "print(decode_poetry(test_x[0]))\n",
    "decode_poet(test_y[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整数数组必须在输入神经网络之前转换为张量。这种转换可以通过以下两种方式来完成：\n",
    "将数组转换为表示单词出现与否的由 0 和 1 组成的向量，类似于 one-hot 编码。例如，序列[3, 5]将转换为一个 10,000 维的向量，该向量除了索引为 3 和 5 的位置是 1 以外，其他都为 0。然后，将其作为网络的首层——一个可以处理浮点型向量数据的稠密层。不过，这种方法需要大量的内存，需要一个大小为 num_words * num_reviews 的矩阵。\n",
    "或者，我们可以填充数组来保证输入数据具有相同的长度，然后创建一个大小为 max_length * num_reviews 的整型张量。我们可以使用能够处理此形状数据的嵌入层作为网络中的第一层。\n",
    "在本教程中，我们将使用第二种方法。\n",
    "由于电影评论长度必须相同，我们将使用 pad_sequences 函数来使长度标准化："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "print(max(map(len, train_x)))\n",
    "print(max(map(len, test_x)))\n",
    "# 不妙，数据处理的时候应当限制为五言、七言、绝句、律诗"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "                  0\ncount  23877.000000\nmean      65.490849\nstd       85.064456\nmin       12.000000\n25%       40.000000\n50%       48.000000\n75%       60.000000\nmax     4500.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>23877.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>65.490849</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>85.064456</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>48.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>60.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4500.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(map(len, train_x))\n",
    "import pandas as pd\n",
    "l_df = pd.DataFrame(l)\n",
    "l_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "vocab_size = 7611\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_x,\n",
    "                                                        value=vocab_size,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=65)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_x,\n",
    "                                                       value=vocab_size,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=65)\n",
    "# 假入强行56，会怎么样？  TODO 可以改为4500"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "露冷風輕霽魄圓，高樓更在碧山巔。四溟水合疑無地，夜深獨與岩僧語，群動消聲舉世眠。\n"
     ]
    },
    {
     "data": {
      "text/plain": "(65, 65)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(decode_poetry([i for i in test_data[0] if i != vocab_size]))\n",
    "len(train_data[0]), len(train_data[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n"
     ]
    }
   ],
   "source": [
    "print(set(train_y))\n",
    "print(set(test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 16)          121792    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               1700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,492\n",
      "Trainable params: 123,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 输入形状是用于诗词的汉字数目（7611 词）\n",
    "vocab_size = 7611\n",
    "poets = 100\n",
    "\n",
    "model = keras.Sequential()\n",
    "# 第一维始终是batch的大小。\n",
    "model.add(keras.layers.Embedding(vocab_size+1, 16)) # 变成16个字\n",
    "# 官方解释：查找每个词索引的嵌入向量（embedding vector）\n",
    "# 嵌入向量是16维的。\n",
    "# 对于一系列batch的数据，把bx56 嵌入到b个 不知道多长的，每个单词变长16维向量的一个向量\n",
    "model.add(keras.layers.GlobalAveragePooling1D()) # 把变长的张量变长定长的？\n",
    "# 对于每一个 嵌入向量，每个单词16维，一句话不定长，直接把一句话的词向量求平均加起来。\n",
    "# model.add(keras.layers.Dense(256, activation='relu')) # （输出为）16个单元的全连接层。\n",
    "# model.add(keras.layers.Dense(1600, activation='relu')) # （输出为）16个单元的全连接层。\n",
    "model.add(keras.layers.Dense(poets, activation='softmax')) #对上一层的结构dense为一个，然后sigmoid？\n",
    "\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "747/747 [==============================] - 2s 2ms/step - loss: 4.4024 - accuracy: 0.0873\n",
      "Epoch 2/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 4.2697 - accuracy: 0.0887\n",
      "Epoch 3/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 4.2074 - accuracy: 0.0925\n",
      "Epoch 4/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 4.1549 - accuracy: 0.0972\n",
      "Epoch 5/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 4.1057 - accuracy: 0.1013\n",
      "Epoch 6/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 4.0560 - accuracy: 0.1105\n",
      "Epoch 7/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 4.0055 - accuracy: 0.1231\n",
      "Epoch 8/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 3.9527 - accuracy: 0.1338\n",
      "Epoch 9/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 3.8970 - accuracy: 0.1413\n",
      "Epoch 10/10\n",
      "747/747 [==============================] - 1s 2ms/step - loss: 3.8373 - accuracy: 0.1509\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_y, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 - 0s - loss: 3.8942 - accuracy: 0.1430 - 279ms/epoch - 1ms/step\n",
      "[3.8941891193389893, 0.14304856956005096]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,  test_y, verbose=2)\n",
    "print(results)  # 好垃圾，没有加隐藏层，对测试集反而好呢"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['loss', 'accuracy'])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "loss = history_dict['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# “bo”代表 \"蓝点\"\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# b代表“蓝色实线”\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_10\" (type Sequential).\n\nInput 0 of layer \"global_average_pooling1d_10\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (56, 16)\n\nCall arguments received by layer \"sequential_10\" (type Sequential):\n  • inputs=tf.Tensor(shape=(56,), dtype=int32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [105]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\EnglishStandardPath\\DevProgramsFile\\Python\\python39\\lib\\site-packages\\keras\\engine\\input_spec.py:214\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[1;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[0;32m    212\u001B[0m   ndim \u001B[38;5;241m=\u001B[39m shape\u001B[38;5;241m.\u001B[39mrank\n\u001B[0;32m    213\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;241m!=\u001B[39m spec\u001B[38;5;241m.\u001B[39mndim:\n\u001B[1;32m--> 214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    215\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis incompatible with the layer: \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    216\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexpected ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, found ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    217\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFull shape received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(shape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mmax_ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    219\u001B[0m   ndim \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n\nInput 0 of layer \"global_average_pooling1d_10\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (56, 16)\n\nCall arguments received by layer \"sequential_10\" (type Sequential):\n  • inputs=tf.Tensor(shape=(56,), dtype=int32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# model(train_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}